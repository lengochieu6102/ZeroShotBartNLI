{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'BenchmarkingZeroShot/topic/train_pu_half_v0.txt'\n",
    "\n",
    "with open(filename) as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 2, 4, 6, 8}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data[0].strip()\n",
    "line_co=0\n",
    "exam_co = 0\n",
    "examples=[]\n",
    "seen_types = set()\n",
    "\n",
    "for row in data:\n",
    "    line = row.strip().split('\\t')\n",
    "    if len(line) == 2: # label_id, text\n",
    "        type_index = int(line[0])\n",
    "        seen_types.add(type_index)\n",
    "\n",
    "seen_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "\n",
    "        Args:\n",
    "            guid: Unique id for the example.\n",
    "            text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "            Only must be specified for sequence pair tasks.\n",
    "            label: (Optional) string. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "type2hypothesis = {\n",
    "0: ['it is related with society or culture', 'this text  describes something about an extended social group having a distinctive cultural and economic organization or a particular society at a particular time and place'],\n",
    "1:['it is related with science or mathematics', 'this text  describes something about a particular branch of scientific knowledge or a science (or group of related sciences) dealing with the logic of quantity and shape and arrangement'],\n",
    "2: ['it is related with health', 'this text  describes something about a healthy state of wellbeing free from disease'],\n",
    "3: ['it is related with education or reference', 'this text  describes something about the activities of educating or instructing or activities that impart knowledge or skill or an indicator that orients you generally'],\n",
    "4: ['it is related with computers or Internet', 'this text  describes something about a machine for performing calculations automatically or a computer network consisting of a worldwide network of computer networks that use the TCP/IP network protocols to facilitate data transmission and exchange'],\n",
    "5: ['it is related with sports', 'this text  describes something about an active diversion requiring physical exertion and competition'],\n",
    "6: ['it is related with business or finance', 'this text  describes something about a commercial or industrial enterprise and the people who constitute it or the commercial activity of providing funds and capital'],\n",
    "7: ['it is related with entertainment or music', 'this text  describes something about an activity that is diverting and that holds the attention or an artistic form of auditory communication incorporating instrumental or vocal tones in a structured and continuous manner'],\n",
    "8: ['it is related with family or relationships', 'this text  describes something about a social unit living together, primary social group; parents and children or a relation between people'],\n",
    "9: ['it is related with politics or government', 'this text  describes something about social relations involving intrigue to gain authority or power or the organization that is the governing authority of a political unit']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training size: 10000\n",
      "loading training size: 20000\n",
      "loading training size: 30000\n",
      "loading training size: 40000\n",
      "loading training size: 50000\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "type2hypothesis = {\n",
    "0: ['it is related with society or culture', 'this text  describes something about an extended social group having a distinctive cultural and economic organization or a particular society at a particular time and place'],\n",
    "1:['it is related with science or mathematics', 'this text  describes something about a particular branch of scientific knowledge or a science (or group of related sciences) dealing with the logic of quantity and shape and arrangement'],\n",
    "2: ['it is related with health', 'this text  describes something about a healthy state of wellbeing free from disease'],\n",
    "3: ['it is related with education or reference', 'this text  describes something about the activities of educating or instructing or activities that impart knowledge or skill or an indicator that orients you generally'],\n",
    "4: ['it is related with computers or Internet', 'this text  describes something about a machine for performing calculations automatically or a computer network consisting of a worldwide network of computer networks that use the TCP/IP network protocols to facilitate data transmission and exchange'],\n",
    "5: ['it is related with sports', 'this text  describes something about an active diversion requiring physical exertion and competition'],\n",
    "6: ['it is related with business or finance', 'this text  describes something about a commercial or industrial enterprise and the people who constitute it or the commercial activity of providing funds and capital'],\n",
    "7: ['it is related with entertainment or music', 'this text  describes something about an activity that is diverting and that holds the attention or an artistic form of auditory communication incorporating instrumental or vocal tones in a structured and continuous manner'],\n",
    "8: ['it is related with family or relationships', 'this text  describes something about a social unit living together, primary social group; parents and children or a relation between people'],\n",
    "9: ['it is related with politics or government', 'this text  describes something about social relations involving intrigue to gain authority or power or the organization that is the governing authority of a political unit']}\n",
    "\n",
    "type_load_size = defaultdict(int)\n",
    "\n",
    "for row in data:\n",
    "    line = row.strip().split('\\t')\n",
    "    if len(line) == 2: # label_id, text\n",
    "        type_index = int(line[0])\n",
    "        if type_load_size.get(type_index, 0) < 10000:\n",
    "            for i in range(10):\n",
    "                hypo_list = type2hypothesis.get(i)\n",
    "                if i == type_index:\n",
    "                    '''pos pair'''\n",
    "                    for hypo in hypo_list:\n",
    "                        guid = \"train-\"+str(exam_co)\n",
    "                        text_a = line[1]\n",
    "                        text_b = hypo\n",
    "                        label = 'entailment' #if line[0] == '1' else 'not_entailment'\n",
    "                        examples.append(\n",
    "                            InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "                        exam_co+=1\n",
    "                elif i in seen_types:\n",
    "                    '''neg pair'''\n",
    "                    for hypo in hypo_list:\n",
    "                        guid = \"train-\"+str(exam_co)\n",
    "                        text_a = line[1]\n",
    "                        text_b = hypo\n",
    "                        label = 'not_entailment' #if line[0] == '1' else 'not_entailment'\n",
    "                        examples.append(\n",
    "                            InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "                        exam_co+=1\n",
    "            line_co+=1\n",
    "            if line_co % 10000 == 0:\n",
    "                print('loading training size:', line_co)\n",
    "\n",
    "            type_load_size[type_index]+=1\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {'2': [1]})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "a = defaultdict(list)\n",
    "a['2'].append(1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test size: 1000\n",
      "loading test size: 2000\n",
      "loading test size: 3000\n",
      "loading test size: 4000\n",
      "loading test size: 5000\n",
      "loading test size: 6000\n",
      "loading test size: 7000\n",
      "loading test size: 8000\n",
      "loading test size: 9000\n",
      "loading test size: 10000\n",
      "loading test size: 11000\n",
      "loading test size: 12000\n",
      "loading test size: 13000\n",
      "loading test size: 14000\n",
      "loading test size: 15000\n",
      "loading test size: 16000\n",
      "loading test size: 17000\n",
      "loading test size: 18000\n",
      "loading test size: 19000\n",
      "loading test size: 20000\n",
      "loading test size: 21000\n",
      "loading test size: 22000\n",
      "loading test size: 23000\n",
      "loading test size: 24000\n",
      "loading test size: 25000\n",
      "loading test size: 26000\n",
      "loading test size: 27000\n",
      "loading test size: 28000\n",
      "loading test size: 29000\n",
      "loading test size: 30000\n",
      "loading test size: 31000\n",
      "loading test size: 32000\n",
      "loading test size: 33000\n",
      "loading test size: 34000\n",
      "loading test size: 35000\n",
      "loading test size: 36000\n",
      "loading test size: 37000\n",
      "loading test size: 38000\n",
      "loading test size: 39000\n",
      "loading test size: 40000\n",
      "loading test size: 41000\n",
      "loading test size: 42000\n",
      "loading test size: 43000\n",
      "loading test size: 44000\n",
      "loading test size: 45000\n",
      "loading test size: 46000\n",
      "loading test size: 47000\n",
      "loading test size: 48000\n",
      "loading test size: 49000\n",
      "loading test size: 50000\n",
      "loading test size: 51000\n",
      "loading test size: 52000\n",
      "loading test size: 53000\n",
      "loading test size: 54000\n",
      "loading test size: 55000\n",
      "loading test size: 56000\n",
      "loading test size: 57000\n",
      "loading test size: 58000\n",
      "loading test size: 59000\n",
      "loading test size: 60000\n",
      "loading test size: 61000\n",
      "loading test size: 62000\n",
      "loading test size: 63000\n",
      "loading test size: 64000\n",
      "loading test size: 65000\n",
      "loading test size: 66000\n",
      "loading test size: 67000\n",
      "loading test size: 68000\n",
      "loading test size: 69000\n",
      "loading test size: 70000\n",
      "loading test size: 71000\n",
      "loading test size: 72000\n",
      "loading test size: 73000\n",
      "loading test size: 74000\n",
      "loading test size: 75000\n",
      "loading test size: 76000\n",
      "loading test size: 77000\n",
      "loading test size: 78000\n",
      "loading test size: 79000\n",
      "loading test size: 80000\n",
      "loading test size: 81000\n",
      "loading test size: 82000\n",
      "loading test size: 83000\n",
      "loading test size: 84000\n",
      "loading test size: 85000\n",
      "loading test size: 86000\n",
      "loading test size: 87000\n",
      "loading test size: 88000\n",
      "loading test size: 89000\n",
      "loading test size: 90000\n",
      "loading test size: 91000\n",
      "loading test size: 92000\n",
      "loading test size: 93000\n",
      "loading test size: 94000\n",
      "loading test size: 95000\n",
      "loading test size: 96000\n",
      "loading test size: 97000\n",
      "loading test size: 98000\n",
      "loading test size: 99000\n",
      "loading test size: 100000\n"
     ]
    }
   ],
   "source": [
    "filename = 'BenchmarkingZeroShot/topic/test.txt'\n",
    "with open(filename) as f:\n",
    "    data = f.readlines()\n",
    "line_co = 0 \n",
    "exam_co = 0\n",
    "examples = []\n",
    "\n",
    "hypo_seen_str_indicator=[]\n",
    "hypo_2_type_index=[]\n",
    "for i in range(10):\n",
    "    hypo_list = type2hypothesis.get(i)\n",
    "    for hypo in hypo_list:\n",
    "        hypo_2_type_index.append(i) # this hypo is for type i\n",
    "        if i in seen_types:\n",
    "            hypo_seen_str_indicator.append('seen')# this hypo is for a seen type\n",
    "        else:\n",
    "            hypo_seen_str_indicator.append('unseen')\n",
    "gold_label_list = []\n",
    "for row in data:\n",
    "    line=row.strip().split('\\t')\n",
    "    if len(line)==2: # label_id, text\n",
    "\n",
    "        type_index =  int(line[0])\n",
    "        gold_label_list.append(type_index)\n",
    "        for i in range(10):\n",
    "            hypo_list = type2hypothesis.get(i)\n",
    "            if i == type_index:\n",
    "                '''pos pair'''\n",
    "                for hypo in hypo_list:\n",
    "                    guid = \"test-\"+str(exam_co)\n",
    "                    text_a = line[1]\n",
    "                    text_b = hypo\n",
    "                    label = 'entailment' #if line[0] == '1' else 'not_entailment'\n",
    "                    examples.append(\n",
    "                        InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "                    exam_co+=1\n",
    "            else:\n",
    "                '''neg pair'''\n",
    "                for hypo in hypo_list:\n",
    "                    guid = \"test-\"+str(exam_co)\n",
    "                    text_a = line[1]\n",
    "                    text_b = hypo\n",
    "                    label = 'not_entailment' #if line[0] == '1' else 'not_entailment'\n",
    "                    examples.append(\n",
    "                        InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "                    exam_co+=1\n",
    "        line_co+=1\n",
    "        if line_co % 1000 == 0:\n",
    "            print('loading test size:', line_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.12k/1.12k [00:00<00:00, 865kB/s]\n",
      "Downloading: 100%|██████████| 899k/899k [00:05<00:00, 170kB/s]  \n",
      "Downloading: 100%|██████████| 456k/456k [00:03<00:00, 132kB/s]  \n",
      "Downloading: 100%|██████████| 772/772 [00:00<00:00, 384kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('valhalla/bart-large-sst2')\n",
    "ex = tokenizer(\n",
    "    ['abc ab', 'abd dasdf'],\n",
    "    ['sadf as', 'asdf asd'],\n",
    "    max_length= 20,\n",
    "    padding= 'max_length',\n",
    "    truncation= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>abc ab</s></s>sadf as</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
       " '<s>abd dasdf</s></s>asdf asd</s><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(ex['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "for i in x:\n",
    "    print(i in [1,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Namespace(conda_env='ligning', model_checkpoint='facebook/bart-base', debuging=True, batch_size=16, data_train_path='', logger=True, enable_checkpointing=True, default_root_dir=None, gradient_clip_val=None, gradient_clip_algorithm=None, num_nodes=1, num_processes=None, devices=None, gpus=None, auto_select_gpus=False, tpu_cores=None, ipus=None, enable_progress_bar=True, overfit_batches=0.0, track_grad_norm=-1, check_val_every_n_epoch=1, fast_dev_run=False, accumulate_grad_batches=None, max_epochs=None, min_epochs=None, max_steps=-1, min_steps=None, max_time=None, limit_train_batches=None, limit_val_batches=None, limit_test_batches=None, limit_predict_batches=None, val_check_interval=None, log_every_n_steps=50, accelerator=None, strategy=None, sync_batchnorm=False, precision=32, enable_model_summary=True, weights_save_path=None, num_sanity_val_steps=2, resume_from_checkpoint=None, profiler=None, benchmark=None, deterministic=None, reload_dataloaders_every_n_epochs=0, auto_lr_find=False, replace_sampler_ddp=True, detect_anomaly=False, auto_scale_batch_size=False, plugins=None, amp_backend='native', amp_level=None, move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle')\n",
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.out_proj.weight', 'classification_head.out_proj.bias', 'classification_head.dense.weight', 'classification_head.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "#0: 100%|█████████████████████████████████████████| 3/3 [00:00<00:00,  3.04ba/s]\n",
      "\n",
      "#1:   0%|                                                 | 0/3 [00:00<?, ?ba/s]\u001b[A\n",
      "#1:  33%|█████████████▋                           | 1/3 [00:00<00:01,  1.99ba/s]\u001b[A\n",
      "#1:  67%|███████████████████████████▎             | 2/3 [00:00<00:00,  2.12ba/s]\u001b[A\n",
      "#1: 100%|█████████████████████████████████████████| 3/3 [00:01<00:00,  2.61ba/s]\u001b[A\n",
      "\n",
      "\n",
      "#2:   0%|                                                 | 0/3 [00:00<?, ?ba/s]\u001b[A\u001b[A\n",
      "\n",
      "#2:  33%|█████████████▋                           | 1/3 [00:00<00:00,  2.02ba/s]\u001b[A\u001b[A\n",
      "\n",
      "#2:  67%|███████████████████████████▎             | 2/3 [00:00<00:00,  2.19ba/s]\u001b[A\u001b[A\n",
      "\n",
      "#2: 100%|█████████████████████████████████████████| 3/3 [00:01<00:00,  2.70ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "#3:   0%|                                                 | 0/3 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "#3:  33%|█████████████▋                           | 1/3 [00:00<00:00,  2.16ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "#3:  67%|███████████████████████████▎             | 2/3 [00:00<00:00,  2.33ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "#3: 100%|█████████████████████████████████████████| 3/3 [00:01<00:00,  2.85ba/s]\u001b[A\u001b[A\u001b[A\n",
      "#0: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  9.27ba/s]\n",
      "\n",
      "#1:   0%|                                                 | 0/1 [00:00<?, ?ba/s]\u001b[A\n",
      "#1: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  8.02ba/s]\u001b[A\n",
      "\n",
      "\n",
      "#2:   0%|                                                 | 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\n",
      "\n",
      "#2: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.12ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "#3:   0%|                                                 | 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "#3: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  9.34ba/s]\u001b[A\u001b[A\u001b[A\n",
      "#0: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.67ba/s]\n",
      "\n",
      "#1:   0%|                                                 | 0/1 [00:00<?, ?ba/s]\u001b[A\n",
      "#1: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.31ba/s]\u001b[A\n",
      "\n",
      "\n",
      "#2:   0%|                                                 | 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\n",
      "\n",
      "#2: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  7.12ba/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "#3:   0%|                                                 | 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "#3: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.54ba/s]\u001b[A\u001b[A\u001b[A\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Finding best initial lr:   1%|▏                 | 1/100 [00:00<00:24,  4.02it/s]Traceback (most recent call last):\n",
      "  File \"/root/hieu/BenchmarkingZeroShot/main.py\", line 91, in <module>\n",
      "    main()\n",
      "  File \"/root/hieu/BenchmarkingZeroShot/main.py\", line 76, in main\n",
      "    lr_finder = trainer.tuner.lr_find(model, datamodule=dm)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/tuner/tuning.py\", line 199, in lr_find\n",
      "    result = self.trainer.tune(\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1052, in tune\n",
      "    result = self.tuner._tune(\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/tuner/tuning.py\", line 70, in _tune\n",
      "    result[\"lr_find\"] = lr_find(self.trainer, model, **lr_find_kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/tuner/lr_finder.py\", line 244, in lr_find\n",
      "    trainer.tuner._run(model)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/tuner/tuning.py\", line 80, in _run\n",
      "    self.trainer._run(*args, **kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1166, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1252, in _run_stage\n",
      "    return self._run_train()\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1283, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py\", line 200, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 271, in advance\n",
      "    self._outputs = self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py\", line 200, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 203, in advance\n",
      "    batch_output = self.batch_loop.run(kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py\", line 200, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 87, in advance\n",
      "    outputs = self.optimizer_loop.run(optimizers, kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py\", line 200, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 201, in advance\n",
      "    result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 248, in _run_optimization\n",
      "    self._optimizer_step(optimizer, opt_idx, kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 358, in _optimizer_step\n",
      "    self.trainer._call_lightning_module_hook(\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1550, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/core/module.py\", line 1705, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 168, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 216, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/plugins/precision/native_amp.py\", line 85, in optimizer_step\n",
      "    closure_result = closure()\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 146, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 132, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 407, in _training_step\n",
      "    training_step_output = self.trainer._call_strategy_hook(\"training_step\", *kwargs.values())\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1704, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 358, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/root/hieu/BenchmarkingZeroShot/lightningmodel.py\", line 50, in training_step\n",
      "    outputs = self(**batch)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/root/hieu/BenchmarkingZeroShot/lightningmodel.py\", line 43, in forward\n",
      "    return self.model(\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py\", line 1516, in forward\n",
      "    outputs = self.model(\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py\", line 1251, in forward\n",
      "    decoder_outputs = self.decoder(\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py\", line 1107, in forward\n",
      "    layer_outputs = decoder_layer(\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py\", line 420, in forward\n",
      "    hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/root/khang/anaconda3/envs/lighning/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py\", line 269, in forward\n",
      "    attn_output = torch.bmm(attn_probs, value_states)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 54.00 MiB (GPU 2; 39.41 GiB total capacity; 8.31 GiB already allocated; 42.56 MiB free; 8.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "!python main.py --debuging=True --batch_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lighning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34092804a187ee7e8b247f3d195a585fdbe37946cb0b644245a20461eb5daf2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
